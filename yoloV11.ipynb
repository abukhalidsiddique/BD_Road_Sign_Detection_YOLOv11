{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e9c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt': 100% ━━━━━━━━━━━━ 38.8MB 358.9KB/s 1:51 1:51<0.1sss\n",
      "Ultralytics 8.3.193  Python-3.10.18 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:/Thesis/YoloVersion11/BRSDD/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=road_signs_training, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=29\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1433383  ultralytics.nn.modules.head.Detect           [29, [256, 512, 512]]         \n",
      "YOLO11m summary: 231 layers, 20,075,367 parameters, 20,075,351 gradients, 68.3 GFLOPs\n",
      "\n",
      "Transferred 643/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 300.0KB/s 18.3s8.3s<0.1s0s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 440.8253.6 MB/s, size: 67.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Thesis\\YoloVersion11\\BRSDD\\train\\labels.cache... 7117 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7117/7117  0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mD:\\Thesis\\YoloVersion11\\BRSDD\\train\\images\\School_ahead_187_jpg.rf.f005ae40434dfdb73d6ffa1dc9e7e986.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.0 ms, read: 44.314.0 MB/s, size: 56.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Thesis\\YoloVersion11\\BRSDD\\valid\\labels.cache... 1024 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1024/1024  0.0s\n",
      "Plotting labels to D:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000303, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      7.91G     0.5296      1.878      1.015         19        640: 100% ━━━━━━━━━━━━ 445/445 0.5it/s 14:29<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.7it/s 11.7s0.4s\n",
      "                   all       1024       1026      0.753      0.862      0.885      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      8.04G     0.5289     0.8726     0.9914         30        640: 100% ━━━━━━━━━━━━ 445/445 0.5it/s 14:02<2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.1it/s 15.5s0.5s\n",
      "                   all       1024       1026      0.836      0.816      0.846      0.752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      8.12G     0.5286     0.7432     0.9928         30        640: 100% ━━━━━━━━━━━━ 445/445 0.5it/s 14:07<2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.0it/s 15.6s0.5s\n",
      "                   all       1024       1026      0.821      0.915      0.922      0.843\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      8.04G     0.5167     0.6527     0.9884         25        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 12:46<1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.5s0.4s\n",
      "                   all       1024       1026      0.879      0.922      0.958       0.88\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      8.11G      0.477     0.5812     0.9679         28        640: 100% ━━━━━━━━━━━━ 445/445 0.9it/s 8:21<1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.2it/s 14.7s0.4s\n",
      "                   all       1024       1026      0.896      0.972      0.971      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      8.11G     0.4524     0.5156     0.9517         18        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 13:27<1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.4s0.4s\n",
      "                   all       1024       1026      0.905      0.955      0.976      0.918\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      8.11G       0.43      0.459     0.9416         20        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 12:45<1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.4s0.4s\n",
      "                   all       1024       1026      0.944      0.982      0.989      0.938\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      8.04G     0.4196     0.4412     0.9373         15        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 12:16<1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.3s0.4s\n",
      "                   all       1024       1026      0.949      0.991      0.992      0.944\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      8.11G     0.3981     0.4083     0.9279         25        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 13:11<1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 1.6it/s 19.7s0.5s\n",
      "                   all       1024       1026      0.968      0.981      0.991      0.946\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       8.1G     0.3902     0.3808     0.9248         30        640: 100% ━━━━━━━━━━━━ 445/445 0.5it/s 14:08<1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.1it/s 15.4s0.5s\n",
      "                   all       1024       1026      0.968      0.984      0.992      0.947\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      8.12G     0.3076     0.2497     0.8525         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 11:45<1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.0it/s 15.7s0.5s\n",
      "                   all       1024       1026      0.966      0.986      0.993      0.951\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      8.04G     0.2987      0.225     0.8443         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 11:42<1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.1it/s 15.4s0.5s\n",
      "                   all       1024       1026      0.973      0.994      0.994       0.95\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       8.1G     0.2854     0.2165     0.8372         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 11:53<1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.1it/s 15.3s0.5s\n",
      "                   all       1024       1026      0.955      0.996      0.993      0.956\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      8.11G     0.2787     0.2067      0.838         13        640: 100% ━━━━━━━━━━━━ 445/445 0.9it/s 7:52<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.3it/s 13.8s0.4s\n",
      "                   all       1024       1026      0.954      0.985      0.986      0.952\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      8.11G     0.2662     0.1909     0.8252         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 12:59<1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.5s0.4s\n",
      "                   all       1024       1026      0.979      0.997      0.995      0.964\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      8.04G     0.2578     0.1782     0.8219         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 12:56<1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.5s0.4s\n",
      "                   all       1024       1026      0.982      0.998      0.995      0.963\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      8.11G     0.2508     0.1657     0.8211         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 13:28<2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.4s0.4s\n",
      "                   all       1024       1026      0.971      0.997      0.995      0.967\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       8.1G     0.2416     0.1587       0.82         13        640: 100% ━━━━━━━━━━━━ 445/445 0.8it/s 9:44<1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.2it/s 14.8s0.4s\n",
      "                   all       1024       1026       0.98          1      0.995      0.971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      8.11G     0.2322     0.1489     0.8216         15        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 12:44<1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.4s0.4s\n",
      "                   all       1024       1026      0.978      0.999      0.995       0.97\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      8.04G     0.2259     0.1431     0.8165         13        640: 100% ━━━━━━━━━━━━ 445/445 0.6it/s 11:33<1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.4s0.4s\n",
      "                   all       1024       1026      0.984      0.997      0.995      0.972\n",
      "\n",
      "20 epochs completed in 4.189 hours.\n",
      "Optimizer stripped from D:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training\\weights\\last.pt, 40.6MB\n",
      "Optimizer stripped from D:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training\\weights\\best.pt, 40.6MB\n",
      "\n",
      "Validating D:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training\\weights\\best.pt...\n",
      "Ultralytics 8.3.193  Python-3.10.18 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,052,391 parameters, 0 gradients, 67.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 2.8it/s 11.5s0.3s\n",
      "                   all       1024       1026      0.984      0.997      0.995      0.972\n",
      "            Crossroads         33         33      0.994          1      0.995       0.95\n",
      "    Emergency Stopping         37         37      0.993          1      0.995      0.993\n",
      "Emergency Stopping 250m         22         22      0.989          1      0.995      0.995\n",
      "              Give Way         17         17       0.99          1      0.995      0.954\n",
      "     Height Limit 5-7m         48         48      0.995          1      0.995      0.985\n",
      "        Hospital Ahead         42         42          1       0.93      0.995      0.714\n",
      "        Junction Ahead          5          5       0.96          1      0.995      0.995\n",
      "          Mosque Ahead         80         80      0.999          1      0.995      0.945\n",
      "         No Overtaking         59         59      0.996          1      0.995      0.994\n",
      "        No Pedestrians          5          5      0.959          1      0.995      0.853\n",
      "      No Vehicle Entry         17         17          1          1      0.995      0.995\n",
      "  Pedestrians Crossing         61         61      0.984          1      0.995      0.957\n",
      "     Petrol Pump Ahead         66         66      0.997          1      0.995      0.984\n",
      "          School Ahead         33         33      0.993          1      0.995      0.985\n",
      "       Sharp Left Turn         38         38      0.993          1      0.995      0.994\n",
      "      Sharp Right Turn         36         36      0.992          1      0.995      0.995\n",
      "     Side Road On Left         94         94      0.998          1      0.995       0.99\n",
      "    Side Road On Right         98         98      0.997          1      0.995      0.994\n",
      "         Speed Breaker         45         45      0.994          1      0.995      0.995\n",
      "     Speed Limit 20 km          7          7      0.923          1      0.995      0.995\n",
      "      Speed Limit 40Km         79         79      0.994          1      0.995      0.994\n",
      "      Speed Limit 80Km         31         31          1      0.974      0.995      0.991\n",
      "      Tolls 1 km Ahead          8          8      0.968          1      0.995      0.995\n",
      "           Tolls Ahead          8          8          1          1      0.995      0.995\n",
      "Traffic Merges From Left         16         16      0.984          1      0.995      0.995\n",
      "Traffic Merges From Right          2          2      0.911          1      0.995      0.995\n",
      "            Truck Lane         15         15      0.983          1      0.995      0.995\n",
      "                U Turn         10         10      0.976          1      0.995      0.995\n",
      "       Underpass Ahead         14         14      0.983          1      0.995      0.983\n",
      "Speed: 0.2ms preprocess, 8.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Thesis\\YoloVersion11\\runs\\detect\\road_signs_training\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11m.pt\")  # Load a medium-sized pretrained model\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=\"D:/Thesis/YoloVersion11/BRSDD/data.yaml\",  # Use forward slashes or double backslashes\n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    batch=16,          # Adjust based on your GPU memory (RTX 4060 can handle 16+)\n",
    "    device=0,          # Use GPU 0 (your RTX 4060)\n",
    "    name=\"road_signs_training\",\n",
    "    patience=50,       # Stop training if no improvement for 50 epochs\n",
    "    optimizer=\"auto\",   # Automatically select the best optimizer\n",
    "    lr0=0.01,          # Initial learning rate\n",
    "    lrf=0.01,          # Final learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924e60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.193  Python-3.10.18 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,052,391 parameters, 0 gradients, 67.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.60.5 ms, read: 4.71.8 MB/s, size: 55.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Thesis\\YoloVersion11\\BRSDD\\test\\labels... 812 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 812/812 507.3it/s 1.6s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Thesis\\YoloVersion11\\BRSDD\\test\\labels.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 51/51 3.7it/s 13.6s0.3s\n",
      "                   all        812        816       0.99      0.999      0.995      0.977\n",
      "            Crossroads         17         17      0.988          1      0.995      0.982\n",
      "    Emergency Stopping         26         26       0.99          1      0.995      0.995\n",
      "Emergency Stopping 250m         18         18      0.989          1      0.995      0.995\n",
      "              Give Way         15         15      0.984          1      0.995      0.962\n",
      "     Height Limit 5-7m         46         46      0.995          1      0.995       0.99\n",
      "        Hospital Ahead         20         20      0.998          1      0.995      0.735\n",
      "        Junction Ahead          6          6          1          1      0.995      0.977\n",
      "          Mosque Ahead         57         57      0.998          1      0.995      0.958\n",
      "         No Overtaking         50         50      0.995          1      0.995      0.992\n",
      "        No Pedestrians         12         12      0.982          1      0.995      0.976\n",
      "      No Vehicle Entry         21         21          1          1      0.995      0.993\n",
      "  Pedestrians Crossing         57         57          1      0.991      0.995      0.961\n",
      "     Petrol Pump Ahead         66         66      0.997          1      0.995      0.972\n",
      "          School Ahead         29         29      0.993          1      0.995      0.982\n",
      "       Sharp Left Turn         26         26       0.99          1      0.995      0.982\n",
      "      Sharp Right Turn         30         30      0.992          1      0.995      0.995\n",
      "     Side Road On Left         77         77      0.996          1      0.995      0.986\n",
      "    Side Road On Right         77         77          1      0.976      0.995      0.994\n",
      "         Speed Breaker         31         31      0.992          1      0.995      0.988\n",
      "     Speed Limit 20 km          3          3      0.934          1      0.995      0.995\n",
      "      Speed Limit 40Km         43         43      0.996          1      0.995      0.995\n",
      "      Speed Limit 80Km         27         27      0.991          1      0.995      0.993\n",
      "      Tolls 1 km Ahead          6          6      0.963          1      0.995      0.995\n",
      "           Tolls Ahead          5          5          1          1      0.995      0.995\n",
      "Traffic Merges From Left         18         18      0.986          1      0.995      0.995\n",
      "            Truck Lane          8          8      0.971          1      0.995      0.995\n",
      "                U Turn          7          7          1          1      0.995      0.995\n",
      "       Underpass Ahead         18         18          1          1      0.995      0.993\n",
      "Speed: 0.3ms preprocess, 14.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Thesis\\YoloVersion11\\runs\\detect\\val\u001b[0m\n",
      "\n",
      "--- Validation Results on Test Set ---\n",
      "Precision: 0.9899245442051461\n",
      "Recall: 0.9988400088207487\n",
      "mAP50: 0.9950000000000001\n",
      "mAP50-95: 0.9773434284664948\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your custom trained model\n",
    "model = YOLO(\"runs/detect/road_signs_training/weights/best.pt\")\n",
    "\n",
    "# Run validation on the test set\n",
    "metrics = model.val(\n",
    "    data=\"D:/Thesis/YoloVersion11/BRSDD/data.yaml\",\n",
    "    split=\"test\",  # Use the 'test' split\n",
    "    device=0       # Use GPU\n",
    ")\n",
    "\n",
    "# Print all available metrics\n",
    "print(\"\\n--- Validation Results on Test Set ---\")\n",
    "print(f\"Precision: {metrics.box.mp}\")  # Precision\n",
    "print(f\"Recall: {metrics.box.mr}\")     # Recall\n",
    "print(f\"mAP50: {metrics.box.map50}\")   # mAP@0.5\n",
    "print(f\"mAP50-95: {metrics.box.map}\")  # mAP@0.5:0.95\n",
    "\n",
    "# You can also access class-wise metrics\n",
    "# print(metrics.box.class_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04eb86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Thesis\\YoloVersion11\\BRSDD\\test\\images\\Narrow_crossing_road_ahead_55_jpg.rf.35fcf2728ccb2af4f9b82a40aea97b8c.jpg: 640x640 1 Crossroads, 55.9ms\n",
      "Speed: 4.4ms preprocess, 55.9ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mD:\\Thesis\\YoloVersion11\\runs\\detect\\predict\u001b[0m\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.9802], device='cuda:0')\n",
      "data: tensor([[ 47.7215,  80.6328, 517.9421, 319.9399,   0.9802,   0.0000]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[282.8318, 200.2863, 470.2206, 239.3071]], device='cuda:0')\n",
      "xywhn: tensor([[0.4419, 0.3129, 0.7347, 0.3739]], device='cuda:0')\n",
      "xyxy: tensor([[ 47.7215,  80.6328, 517.9421, 319.9399]], device='cuda:0')\n",
      "xyxyn: tensor([[0.0746, 0.1260, 0.8093, 0.4999]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your custom trained model\n",
    "model = YOLO(\"runs/detect/road_signs_training/weights/best.pt\")\n",
    "\n",
    "# Run inference on an image\n",
    "results = model.predict(\n",
    "    source=\"D:/Thesis/YoloVersion11/BRSDD/test/images/Narrow_crossing_road_ahead_55_jpg.rf.35fcf2728ccb2af4f9b82a40aea97b8c.jpg\",  # Replace with your test image path\n",
    "    conf=0.25,    # Confidence threshold\n",
    "    device=0,     # Use GPU\n",
    "    save=True     # Save results\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(results[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ce0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Thesis\\YoloVersion11\\BRSDD\\test\\images\\No_overtaking_209_jpg.rf.8e1dac252f0285070475eba375aec72f.jpg: 640x640 1 No Overtaking, 92.4ms\n",
      "Speed: 3.7ms preprocess, 92.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mD:\\Thesis\\YoloVersion11\\runs\\detect\\predict2\u001b[0m\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([8.], device='cuda:0')\n",
      "conf: tensor([0.9734], device='cuda:0')\n",
      "data: tensor([[ 69.2109,  30.8074, 507.7547, 303.2070,   0.9734,   8.0000]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[288.4828, 167.0072, 438.5438, 272.3997]], device='cuda:0')\n",
      "xywhn: tensor([[0.4508, 0.2609, 0.6852, 0.4256]], device='cuda:0')\n",
      "xyxy: tensor([[ 69.2109,  30.8074, 507.7547, 303.2070]], device='cuda:0')\n",
      "xyxyn: tensor([[0.1081, 0.0481, 0.7934, 0.4738]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your custom trained model\n",
    "model = YOLO(\"runs/detect/road_signs_training/weights/best.pt\")\n",
    "\n",
    "# Run inference on an image\n",
    "results = model.predict(\n",
    "    source=\"D:/Thesis/YoloVersion11/BRSDD/test/images/No_overtaking_209_jpg.rf.8e1dac252f0285070475eba375aec72f.jpg\",  # Replace with your test image path\n",
    "    conf=0.25,    # Confidence threshold\n",
    "    device=0,     # Use GPU\n",
    "    save=True     # Save results\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(results[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea222d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
